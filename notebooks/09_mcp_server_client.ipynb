{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df802839-34b5-4169-88fd-73685ce01912",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<p align=\"center\" style=\"width: 100%;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/vlm-run/.github/refs/heads/main/profile/assets/vlm-black.svg\" alt=\"VLM Run Logo\" width=\"80\" style=\"margin-bottom: -5px; color: #2e3138; vertical-align: middle; padding-right: 5px;\"><br>\n",
    "</p>\n",
    "<p align=\"center\"><a href=\"https://vlm.run\"><b>Website</b></a> | <a href=\"https://app.vlm.run/\"><b>Platform</b></a> | <a href=\"https://github.com/vlm-run/vlmrun-hub\"><b>Hub</b></a> | <a href=\"https://docs.vlm.run/\"><b>Docs</b></a> | <a href=\"https://vlm.run/blog\"><b>Blog</b></a> | <a href=\"https://discord.gg/4jgyECY4rq\"><b>Discord</b></a>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<a href=\"https://discord.gg/4jgyECY4rq\"><img alt=\"Discord\" src=\"https://img.shields.io/badge/discord-chat-purple?color=%235765F2&label=discord&logo=discord\"></a>\n",
    "<a href=\"https://twitter.com/vlmrun\"><img alt=\"Twitter Follow\" src=\"https://img.shields.io/badge/twitter-follow-blue?color=%231DA1F2&label=twitter&logo=twitter\"></a>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "This notebook demonstrates how to use the **VLM Run MCP Server** with OpenAI Responses API. The VLM Run MCP Server provides access to powerful visual AI capabilities through the Model Context Protocol (MCP).\n",
    "\n",
    "## What is VLM Run MCP Server?\n",
    "\n",
    "The VLM Run MCP Server transforms any MCP-compatible AI agent into a visual AI powerhouse. It provides access to:\n",
    "\n",
    "- **Document AI**: Extract structured data from invoices, receipts, contracts, forms\n",
    "- **Image AI**: Classify images, extract text, analyze visual content, detect objects and faces\n",
    "- **Video AI**: Transcribe videos with scene descriptions, search content, edit videos\n",
    "- **Hub Management**: Browse 50+ pre-built domains and create custom schemas\n",
    "\n",
    "**Server URL**: `https://mcp.vlm.run/mcp/sse`  \n",
    "**Authentication**: Bearer token (VLM Run API key)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.9+\n",
    "- VLM Run API key (get one at [app.vlm.run](https://app.vlm.run))\n",
    "- OpenAI API key (for OpenAI examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8194644-eead-4193-90dd-ffbaf8dccafe",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9c7bc7-b4df-429b-a925-9e6a8be3b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5711959-0eaa-41d9-ba51-3b2b0659de4e",
   "metadata": {},
   "source": [
    "### 1. OpenAI API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5c9f7e-7e47-40ca-8568-e45f04118d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "VLMRUN_API_KEY = os.getenv(\"VLMRUN_API_KEY\", \"\")\n",
    "VLMRUN_MCP_SERVER_URL = f\"https://mcp.vlm.run/mcp/sse\"\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.Client(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870b43d1-3841-41bf-9817-b4386d0849c7",
   "metadata": {},
   "source": [
    "### 2. Image Processing Examples\n",
    "\n",
    "#### Face Detection and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf46435-fa9b-434b-b039-c54ad4b5cdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Detection Result:\n",
      "Here is the preview URL of the image with all detected faces visualized:\n",
      "[https://mcp.vlm.run/files/img_159f](https://mcp.vlm.run/files/img_159f)\n",
      "\n",
      "The image now displays bounding boxes around each detected face.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[{\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_label\": \"vlm-run-mcp\",\n",
    "        \"server_url\": VLMRUN_MCP_SERVER_URL,\n",
    "        \"headers\": {\n",
    "            \"Authorization\": f\"Bearer {VLMRUN_API_KEY}\"\n",
    "        },\n",
    "        \"require_approval\": \"never\"\n",
    "    }],\n",
    "    input=\"Load this image (https://storage.googleapis.com/vlm-data-public-prod/hub/examples/media.tv-news/finance_bb_3_speakers.jpg) and detect all the faces in the image, visualize the detected faces, and return the preview URL of the visualized image.\"\n",
    ")\n",
    "\n",
    "print(\"Face Detection Result:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b62d3-d59d-4fde-a82c-f86c0dbe8e21",
   "metadata": {},
   "source": [
    "#### Face Blurring and Privacy Protection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7c52f-58d2-4f0f-97b1-d8fefefbd14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Blurring Result:\n",
      "Here is the preview URL of the image with all detected faces blurred, and bounding boxes with \"face\" overlays on the blurred regions:\n",
      "[https://mcp.vlm.run/files/img_a369](https://mcp.vlm.run/files/img_a369)\n",
      "\n",
      "You will see the faces are blurred and labeled/outlined on the image as requested.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[{\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_label\": \"vlm-run-mcp\",\n",
    "        \"server_url\": VLMRUN_MCP_SERVER_URL,\n",
    "        \"headers\": {\n",
    "            \"Authorization\": f\"Bearer {VLMRUN_API_KEY}\"\n",
    "        },\n",
    "        \"require_approval\": \"never\"\n",
    "    }],\n",
    "    input=\"Load this image (https://storage.googleapis.com/vlm-data-public-prod/hub/examples/media.tv-news/finance_bb_3_speakers.jpg) and detect all the faces in the image, blur them, and overlay the detected faces on the blurred image, and return the preview URL of the blurred image.\"\n",
    ")\n",
    "\n",
    "print(\"Face Blurring Result:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd14ac4-d2fd-4ff5-a517-6fdadf81aace",
   "metadata": {},
   "source": [
    "### 3. Document Processing Examples\n",
    "\n",
    "#### Invoice Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d69ca9-68b5-44e2-815c-fd5a427c1a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoice Extraction Result:\n",
      "### Extracted Invoice Details (with Grounding Information)\n",
      "\n",
      "#### Invoice Metadata\n",
      "- **Issuer:** Google  \n",
      "  - **Location:** [Page 0, bbox: [0.06, 0.015, 0.25, 0.067]]\n",
      "- **Invoice Number:** 23413561D  \n",
      "  - **Location:** [Page 0, bbox: [0.81, 0.072, 0.124, 0.016]]\n",
      "- **Invoice Date (Issue):** 2019-09-24 (Sep 24, 2019)  \n",
      "  - **Location:** [Page 0, bbox: [0.83, 0.138, 0.10, 0.016]]\n",
      "- **Invoice Due Date:** 2019-09-30 (Sep 30, 2019)  \n",
      "  - **Location:** [Page 0, bbox: [0.83, 0.166, 0.10, 0.016]]\n",
      "\n",
      "#### Customer Details\n",
      "- **Name:** Jane Smith  \n",
      "  - **Location:** [Page 0, bbox: [0.081, 0.164, 0.093, 0.015]]\n",
      "- **Billing Address:**  \n",
      "  - **Street:** 1600 Amphitheatre Pkway, [Page 0, bbox: [0.082, 0.179, 0.191, 0.016]]\n",
      "  - **City/State/Zip:** Mountain View, CA 94043, [Page 0, bbox: [0.08, 0.195, 0.191, 0.015]]\n",
      "\n",
      "#### Invoice Line Items\n",
      "\n",
      "| Description              | Quantity | Unit Price | Total Price | BBox (Description)                     |\n",
      "|--------------------------|----------|------------|-------------|----------------------------------------|\n",
      "| 12 ft HDMI cable         | 12       | $9.99      | $119.88     | [0.075, 0.305, 0.128, 0.015]          |\n",
      "| 27\" Computer Monitor     | 12       | $399.99    | $4,799.88   | [0.074, 0.326, 0.174, 0.015]          |\n",
      "| Ergonomic Keyboard       | 12       | $59.99     | $719.88     | [0.074, 0.348, 0.167, 0.016]          |\n",
      "| Optical mouse            | 12       | $19.99     | $239.88     | [0.075, 0.371, 0.115, 0.015]          |\n",
      "| Laptop                   | 12       | $1299.99   | $15,599.88  | [0.075, 0.393, 0.056, 0.015]          |\n",
      "| Misc processing fees     | 1        | $899.99    | $899.99     | [0.074, 0.415, 0.167, 0.016]          |\n",
      "\n",
      "#### Summary\n",
      "- **Subtotal:** $22,379.39  \n",
      "  - **Location:** [Page 0, bbox: [0.844, 0.499, 0.085, 0.015]]\n",
      "- **Tax:** $1,767.97  \n",
      "  - **Location:** [Page 0, bbox: [0.853, 0.556, 0.075, 0.015]]\n",
      "- **Total:** $19,647.68  \n",
      "  - **Location:** [Page 0, bbox: [0.844, 0.612, 0.085, 0.015]]\n",
      "\n",
      "#### Notes\n",
      "- **Text:** \"This is a test order. No actual transactions took place.\"  \n",
      "  - **Location:** [Page 0, bbox: [0.079, 0.731, 0.390, 0.016]]\n",
      "\n",
      "---\n",
      "\n",
      "**Bounding boxes** are given in normalized format `[x, y, width, height]` relative to the top-left corner of Page 0.\n",
      "\n",
      "Let me know if you want a visual highlight on the actual invoice PDF for any of the extracted fields!\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[{\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_label\": \"vlm-run-mcp\",\n",
    "        \"server_url\": VLMRUN_MCP_SERVER_URL,\n",
    "        \"headers\": {\n",
    "            \"Authorization\": f\"Bearer {VLMRUN_API_KEY}\"\n",
    "        },\n",
    "        \"require_approval\": \"never\"\n",
    "    }],\n",
    "    input=\"Load this invoice (https://storage.googleapis.com/vlm-data-public-prod/hub/examples/document.invoice/google_invoice.pdf) and extract the invoice details (invoice number, total amount, date, etc.) including its grounding information.\"\n",
    ")\n",
    "\n",
    "print(\"Invoice Extraction Result:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe14789-ad0f-4e73-a605-beb34abbb646",
   "metadata": {},
   "source": [
    "#### PII Redaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deead439-41ca-4318-87b9-4797b151a95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PII Redaction Result:\n",
      "The personal information has been successfully redacted from the document. You can view the processed document [here](https://mcp.vlm.run/files/img_e751).\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[{\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_label\": \"vlm-run-mcp\",\n",
    "        \"server_url\": VLMRUN_MCP_SERVER_URL,\n",
    "        \"headers\": {\n",
    "            \"Authorization\": f\"Bearer {VLMRUN_API_KEY}\"\n",
    "        },\n",
    "        \"require_approval\": \"never\"\n",
    "    }],\n",
    "    input=\"Load this document (https://storage.googleapis.com/vlm-data-public-prod/hub/examples/document.invoice/invoice_1.jpg) and redact any personal information (name, address, phone number, email, etc.) from the document.\"\n",
    ")\n",
    "\n",
    "print(\"PII Redaction Result:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b507666-1794-4eee-8dae-3769babec304",
   "metadata": {},
   "source": [
    "### 4. Hub Schema Management\n",
    "\n",
    "#### List Available Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb89eae-2a71-4166-bfcd-cf9c70be3797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Domains:\n",
      "Here are the first 5 available hub domains with their categories:\n",
      "\n",
      "1. accounting.form-payslip (Category: accounting)\n",
      "2. accounting.form-w2 (Category: accounting)\n",
      "3. aerospace.remote-sensing (Category: aerospace)\n",
      "4. document.bank-check (Category: document)\n",
      "5. document.bank-statement (Category: document)\n",
      "\n",
      "These are schema domains you can use for processing or structuring data related to each category. If you want to see details or fields for any schema, let me know!\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[{\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_label\": \"vlm-run-mcp\",\n",
    "        \"server_url\": VLMRUN_MCP_SERVER_URL,\n",
    "        \"headers\": {\n",
    "            \"Authorization\": f\"Bearer {VLMRUN_API_KEY}\"\n",
    "        },\n",
    "        \"require_approval\": \"never\"\n",
    "    }],\n",
    "    input=\"List all available hub domains and show me the first 5 domains with their categories. I want to see what schemas are available.\"\n",
    ")\n",
    "\n",
    "print(\"Available Domains:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f0e70-42a9-448a-82be-e580876d3d20",
   "metadata": {},
   "source": [
    "#### Get Schema Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da91978-63eb-4dbd-9f8e-0aee2d6411a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoice Schema:\n",
      "Here is the structure and available fields for the JSON schema of the **document.invoice** domain:\n",
      "\n",
      "---\n",
      "\n",
      "### General Information\n",
      "\n",
      "- **Description:** Comprehensive invoice data extraction system that processes invoice images to extract structured information including invoice metadata, customer details, line items, and financial totals.\n",
      "\n",
      "---\n",
      "\n",
      "## Schema Structure & Fields\n",
      "\n",
      "### Top-Level Invoice Fields\n",
      "\n",
      "| Field                        | Type        | Description                       |\n",
      "|------------------------------|-------------|-----------------------------------|\n",
      "| invoice_id                   | string/null | Unique invoice identifier         |\n",
      "| period_start                 | string/date | Invoice period start date         |\n",
      "| period_end                   | string/date | Invoice period end date           |\n",
      "| invoice_issue_date           | string/date | Issue date of the invoice         |\n",
      "| invoice_due_date             | string/date | Due date of the invoice           |\n",
      "| order_id                     | string/null | Unique order identifier           |\n",
      "| customer_id                  | string/null | Unique customer identifier        |\n",
      "| issuer                       | string/null | Issuer of the invoice             |\n",
      "| issuer_address               | object/null | Issuer's address                  |\n",
      "| customer                     | string/null | Recipient of the invoice          |\n",
      "| customer_email               | string/null | Recipient's email                 |\n",
      "| customer_phone               | string/null | Recipient's phone                 |\n",
      "| customer_billing_address     | object/null | Recipient's billing address       |\n",
      "| customer_shipping_address    | object/null | Recipient's shipping address      |\n",
      "| items                        | array/null  | Items in the invoice              |\n",
      "| subtotal                     | number/null | Subtotal of the invoice           |\n",
      "| tax                          | number/null | Tax of the invoice                |\n",
      "| total                        | number/null | Total of the invoice              |\n",
      "| currency                     | string/null | Currency of the invoice           |\n",
      "| notes                        | string/null | Notes of the invoice              |\n",
      "\n",
      "---\n",
      "\n",
      "### Address Object\n",
      "\n",
      "| Field       | Type        | Description      |\n",
      "|-------------|-------------|------------------|\n",
      "| street      | string/null | Street address   |\n",
      "| city        | string/null | City             |\n",
      "| state       | string/null | State            |\n",
      "| postal_code | string/null | Postal code      |\n",
      "| country     | string/null | Country          |\n",
      "\n",
      "---\n",
      "\n",
      "### Item Object (for each line item in items array)\n",
      "\n",
      "| Field        | Type          | Description              |\n",
      "|--------------|---------------|--------------------------|\n",
      "| description  | string/null   | Description/name of item |\n",
      "| quantity     | integer/null  | Quantity                 |\n",
      "| currency     | string/null   | 3-digit currency code    |\n",
      "| unit_price   | number/null   | Unit price               |\n",
      "| total_price  | number/null   | Total price              |\n",
      "\n",
      "---\n",
      "\n",
      "#### Notes:\n",
      "\n",
      "- All fields can be null if not available.\n",
      "- Dates are ISO date strings.\n",
      "- Currency is typically a 3-letter code (e.g., USD, EUR).\n",
      "\n",
      "Let me know if you want the raw JSON schema or have follow-up questions about field usage!\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[{\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_label\": \"vlm-run-mcp\",\n",
    "        \"server_url\": VLMRUN_MCP_SERVER_URL,\n",
    "        \"headers\": {\n",
    "            \"Authorization\": f\"Bearer {VLMRUN_API_KEY}\"\n",
    "        },\n",
    "        \"require_approval\": \"never\"\n",
    "    }],\n",
    "    input=\"Get the JSON schema for the 'document.invoice' domain. Show me the schema structure and available fields.\"\n",
    ")\n",
    "\n",
    "print(\"Invoice Schema:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4996f-c3fe-44a4-a2c3-3b337bb323df",
   "metadata": {},
   "source": [
    "### 5. Advanced Examples\n",
    "\n",
    "#### Face Cropping and Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f654679d-1f6d-4498-89ec-cad983bfbed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Cropping Result:\n",
      "Here is the cropped image of the right-most face, as detected and requested:\n",
      "\n",
      "<img src=\"https://mcp.vlm.run/files/img_62b2\" alt=\"Cropped right-most face\" />\n",
      "\n",
      "You can preview it directly above in HTML. Let me know if you want to analyze or process this face further!\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[{\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_label\": \"vlm-run-mcp\",\n",
    "        \"server_url\": VLMRUN_MCP_SERVER_URL,\n",
    "        \"headers\": {\n",
    "            \"Authorization\": f\"Bearer {VLMRUN_API_KEY}\"\n",
    "        },\n",
    "        \"require_approval\": \"never\"\n",
    "    }],\n",
    "    input=\"Load this image (https://storage.googleapis.com/vlm-data-public-prod/hub/examples/media.tv-news/finance_bb_3_speakers.jpg), detect all the faces in the image, and crop the right-most face, and preview the cropped image in HTML.\"\n",
    ")\n",
    "\n",
    "print(\"Face Cropping Result:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a88b02-7176-4b80-8b45-ee10e2bd89ca",
   "metadata": {},
   "source": [
    "#### Video Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3cd1f-6ace-4abd-be62-c55c99559b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Preview:\n",
      "Here’s an HTML snippet you can use to preview the video using the provided link:\n",
      "\n",
      "```html\n",
      "<video width=\"640\" height=\"360\" controls>\n",
      "  <source src=\"https://storage.googleapis.com/vlm-data-public-prod/hub/examples/video/test_video.mp4\" type=\"video/mp4\">\n",
      "  Your browser does not support the video tag.\n",
      "</video>\n",
      "```\n",
      "\n",
      "**How to use:**\n",
      "- Copy and paste this code into your HTML file or an online HTML editor.\n",
      "- You’ll see a video player with standard controls (play, pause, etc.) for the video.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[{\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_label\": \"vlm-run-mcp\",\n",
    "        \"server_url\": VLMRUN_MCP_SERVER_URL,\n",
    "        \"headers\": {\n",
    "            \"Authorization\": f\"Bearer {VLMRUN_API_KEY}\"\n",
    "        },\n",
    "        \"require_approval\": \"never\"\n",
    "    }],\n",
    "    input=\"Load this video (https://storage.googleapis.com/vlm-data-public-prod/hub/examples/video/test_video.mp4) and preview the video in HTML.\"\n",
    ")\n",
    "\n",
    "print(\"Video Preview:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46140e8e-dc54-4d4c-b566-fc0525ad7653",
   "metadata": {},
   "source": [
    "### 7. Next Steps and Resources\n",
    "\n",
    "#### Explore More Capabilities\n",
    "\n",
    "1. **Advanced Video Processing**: Try video transcription, editing, and analysis\n",
    "2. **Batch Processing**: Process large volumes of documents efficiently\n",
    "3. **Real-time Applications**: Build live video processing applications\n",
    "4. **Multi-modal Analysis**: Combine text, image, and video analysis\n",
    "\n",
    "#### Tool Categories\n",
    "\n",
    "- **Image Processing**: Object detection, OCR, face detection, QR code detection, template matching\n",
    "- **Document Processing**: Invoice extraction, PII redaction, figure detection\n",
    "- **Video Processing**: Video preview, trimming, watermarking, YouTube transcript extraction\n",
    "- **Hub Management**: Schema listing, creation, updating, and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8652779-5432-4516-a789-d3122a105157",
   "metadata": {},
   "source": [
    "#### Resources\n",
    "\n",
    "- [VLM Run MCP Documentation](https://docs.vlm.run/mcp)\n",
    "- [FastMCP Documentation](https://gofastmcp.com)\n",
    "- [VLM Run Hub](https://github.com/vlm-run/vlmrun-hub)\n",
    "- [Discord Community](https://discord.gg/4jgyECY4rq)\n",
    "\n",
    "#### Support\n",
    "\n",
    "- Email: [support@vlm.run](mailto:support@vlm.run)\n",
    "- Discord: [Join our community](https://discord.gg/4jgyECY4rq)\n",
    "- GitHub: [Report issues](https://github.com/vlm-run/vlmrun-hub/issues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
